{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHCNhUTtgmYXYnp13zYZ9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6025f159b0941cebd54c23d663d73df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384de4d2483842128e56ec8003851fa7",
              "IPY_MODEL_4569804c1720490aa151e3b896f52dd7",
              "IPY_MODEL_0c2cbc08915d4d7ab4949ab99993dd46"
            ],
            "layout": "IPY_MODEL_18ff258b8f60414a9bdd26b06b3bb00d"
          }
        },
        "384de4d2483842128e56ec8003851fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3cc8d779e074304bc17f76b9b0168de",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1468144bea42718f73a7362bc29b0e",
            "value": "100%"
          }
        },
        "4569804c1720490aa151e3b896f52dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf669879f80f4e0ebc53a2e0ed0d9bca",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61087736c8c549f3a7c2358408735d9b",
            "value": 1500
          }
        },
        "0c2cbc08915d4d7ab4949ab99993dd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8656ef6341f24908ba41bd373f83213f",
            "placeholder": "​",
            "style": "IPY_MODEL_d262a946beca499e97a57b80bf7be2f7",
            "value": " 1500/1500 [1:11:49&lt;00:00,  2.51s/it]"
          }
        },
        "18ff258b8f60414a9bdd26b06b3bb00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cc8d779e074304bc17f76b9b0168de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1468144bea42718f73a7362bc29b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf669879f80f4e0ebc53a2e0ed0d9bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61087736c8c549f3a7c2358408735d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8656ef6341f24908ba41bd373f83213f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d262a946beca499e97a57b80bf7be2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siruku6/thesis-trial/blob/master/240126_rl_LunarLander_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- task: https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
        "- https://qiita.com/siruku6/items/9b6347ad6c5a891b61f1\n",
        "- https://note.com/npaka/n/n784a13c44fa7\n",
        "\n",
        "- https://www.kaggle.com/c/connectx/overview\n",
        "- https://www.kaggle.com/code/ajeffries/connectx-getting-started\n",
        "- https://www.kaggle.com/code/alexisbcook/deep-reinforcement-learning/tutorial\n",
        "- https://www.kaggle.com/code/toshikazuwatanabe/connect4-make-submission-with-stable-baselines3\n"
      ],
      "metadata": {
        "id": "oBvCfHhXtY6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. install / import module"
      ],
      "metadata": {
        "id": "N9sXpWgsrHRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: gymnasium[box2d] を install するために必要\n",
        "#   swig がないと、\"ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\" が発生する\n",
        "# https://stackoverflow.com/questions/76222239/pip-install-gymnasiumbox2d-not-working-on-google-colab\n",
        "!pip install -q swig\n",
        "\n",
        "!pip install -q gymnasium[box2d]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbZoPB3Ppjl7",
        "outputId": "26f939c3-aecf-4441-afa5-ad0151f3dd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# colabortory 上で gymnasium のゲーム実行結果を録画するためのモジュールインストール\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg\n",
        "!pip install -q pyvirtualdisplay\n"
      ],
      "metadata": {
        "id": "8liaREo-uI5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. LunarLander の動作確認"
      ],
      "metadata": {
        "id": "42qGh8q0r7Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1. 実行結果を録画"
      ],
      "metadata": {
        "id": "dVJMBQzfxWJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab上で仮想ディスプレイを使用するための設定\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "import gym\n",
        "from gym.wrappers import RecordVideo\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n"
      ],
      "metadata": {
        "id": "zvwb4F-i7JUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LunarLander環境の作成\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "# 録画用の RecordVideo ラッパーの作成\n",
        "video_path = \"/content/lunar_lander_video\"  # 保存先\n",
        "env = RecordVideo(env, video_path)\n",
        "\n",
        "# エピソードの実行\n",
        "num_episodes = 5\n",
        "for episode in range(num_episodes):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = env.action_space.sample()  # ランダムな行動の選択\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
        "\n",
        "\n",
        "# 動画の保存先の表示\n",
        "video_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "x2Rx3KeOudIU",
        "outputId": "e1be3e09-3494-4994-a6d0-9630090682c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/lunar_lander_video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment LunarLander-v2 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Total Reward: -109.48552757315353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment LunarLander-v2 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 2, Total Reward: -140.23207423453118\n",
            "Episode 3, Total Reward: -225.84344004730804\n",
            "Episode 4, Total Reward: -342.29615683726183\n",
            "Episode 5, Total Reward: -47.62287418643385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/lunar_lander_video'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2. 出力の形状や値を確認"
      ],
      "metadata": {
        "id": "s5zZotyp6HcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.sample()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhMq9UiJ5_SQ",
        "outputId": "291534ab-1648-416a-89a6-f54e59e65268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZVaICLi6B34",
        "outputId": "69dd6b10-8a33-46a7-fa98-dbf15fb8b4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.5108868 , -0.06801012, -1.3691006 , -0.22762576,  1.1895872 ,\n",
              "        3.6116757 ,  0.        ,  1.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 実装"
      ],
      "metadata": {
        "id": "Bdd-axG-BhiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-1. experience replay 用クラス\n"
      ],
      "metadata": {
        "id": "m7gPSs5tyWvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random\n",
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "20WOd2dMCsBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, buffer_size: int, batch_size: int) -> None:\n",
        "        self.buffer: deque = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done) -> None:\n",
        "        data: Dict[str, Any] = {\n",
        "            \"state\": state,\n",
        "            \"action\": action,\n",
        "            \"reward\": reward,\n",
        "            \"next_state\": next_state,\n",
        "            \"done\": done,\n",
        "        }\n",
        "        self.buffer.append(data)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def pick_batch(self) -> tuple:\n",
        "        batch = random.sample(self.buffer, self.batch_size)\n",
        "\n",
        "        state_batch = np.stack([x[\"state\"] for x in batch], axis=0)\n",
        "        action_batch = np.array([x[\"action\"] for x in batch])\n",
        "        reward_batch = np.array([x[\"reward\"] for x in batch])\n",
        "        next_state_batch = np.stack([x[\"next_state\"] for x in batch], axis=0)\n",
        "        done_batch = np.array([x[\"done\"] for x in batch]).astype(np.int32)\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n"
      ],
      "metadata": {
        "id": "aYMijyYayVeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### experience replay の動作確認"
      ],
      "metadata": {
        "id": "EDKGJeFPBpWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "replay_buf = ReplayBuffer(buffer_size=100, batch_size=10)\n",
        "\n",
        "for episode in range(10):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        replay_buf.add(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "\n",
        "(\n",
        "    state_batch,\n",
        "    action_batch,\n",
        "    reward_batch,\n",
        "    next_state_batch,\n",
        "    done_batch,\n",
        ") = replay_buf.pick_batch()\n",
        "\n",
        "\n",
        "(\n",
        "    state_batch.shape,\n",
        "    action_batch.shape,\n",
        "    reward_batch.shape,\n",
        "    next_state_batch.shape,\n",
        "    done_batch.shape,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFCATtdxBluy",
        "outputId": "b9f18352-304b-4823-d23f-1c8fd1aeb0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10, 8), (10,), (10,), (10, 8), (10,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2. DQN クラス"
      ],
      "metadata": {
        "id": "0vEKUrEwBvHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "5jiqirfNSOM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QNet(nn.Module):\n",
        "    def __init__(self, action_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(8, 128)\n",
        "        self.linear2 = nn.Linear(128, 128)\n",
        "        self.linear3 = nn.Linear(128, action_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self) -> None:\n",
        "        self.gamma: float = 0.98\n",
        "        self.lr: float = 0.0005\n",
        "        # self.epsilon: float = 0.1\n",
        "        self.epsilon: float = 0.075\n",
        "        self.buffer_size: int = 10000\n",
        "        self.batch_size: int = 32\n",
        "        self.action_size: int = 4\n",
        "\n",
        "        self.replay_buffer: tuple = ReplayBuffer(\n",
        "            buffer_size=self.buffer_size,\n",
        "            batch_size=self.batch_size\n",
        "        )\n",
        "\n",
        "        self.qnet = QNet(action_size=self.action_size)\n",
        "        self.qnet_target = QNet(action_size=self.action_size)\n",
        "        self.optimizer = optim.Adam(self.qnet.parameters(), lr=self.lr)\n",
        "\n",
        "    def sync_qnet(self) -> None:\n",
        "        self.qnet_target = copy.deepcopy(self.qnet)\n",
        "\n",
        "    def get_action(self, state: torch.Tensor, deterministic: bool = False) -> int:\n",
        "        if (not deterministic) and (np.random.rand() < self.epsilon):\n",
        "            action: int = np.random.choice(self.action_size)\n",
        "        else:\n",
        "            state = state[np.newaxis, :]  # (8,) -> (1, 8)\n",
        "            torch_state: torch.Tensor = torch.from_numpy(\n",
        "                state.astype(np.float32)\n",
        "            ).float()\n",
        "            qs: torch.Tensor = self.qnet(torch_state)\n",
        "            action: int = qs.data.argmax().item()\n",
        "            # print(\"action from Q:\", action)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update(\n",
        "        self,\n",
        "        state: np.ndarray,\n",
        "        action: int,\n",
        "        reward: np.ndarray,\n",
        "        next_state: np.ndarray,\n",
        "        done: int,\n",
        "    ) -> None:\n",
        "        self.replay_buffer.add(state, action, reward, next_state, done)\n",
        "        if len(self.replay_buffer) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        (\n",
        "            state_batch,\n",
        "            action_batch,\n",
        "            reward_batch,\n",
        "            next_state_batch,\n",
        "            done_batch,\n",
        "        ) = self.replay_buffer.pick_batch()\n",
        "\n",
        "        torch_state_batch: torch.Tensor = torch.from_numpy(\n",
        "            state_batch.astype(np.float32)\n",
        "        )\n",
        "        qs = self.qnet(torch_state_batch)\n",
        "        q = qs[np.arange(self.batch_size), action_batch]\n",
        "\n",
        "        torch_next_state_batch: torch.Tensor = torch.from_numpy(\n",
        "            next_state_batch.astype(np.float32)\n",
        "        )\n",
        "        next_qs = self.qnet_target(torch_next_state_batch)\n",
        "        # next_q = next_q.unchain()\n",
        "        next_qs = next_qs.detach()\n",
        "        # next_q = next_qs.max(axis=1)\n",
        "        next_q = next_qs.max(dim=1).values\n",
        "\n",
        "        torch_reward_batch: torch.Tensor = torch.from_numpy(\n",
        "            reward_batch.astype(np.float32)\n",
        "        )\n",
        "        target = (torch_reward_batch + self.gamma * next_q * (1 - done_batch)).float()\n",
        "\n",
        "        loss_func = nn.MSELoss()\n",
        "        loss = loss_func(q, target)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW73OS2dCp3N",
        "outputId": "ede037ef-a38b-42de-88e2-f42f59f23549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3. DQN の学習"
      ],
      "metadata": {
        "id": "7eFKYjf1B5vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 1500\n",
        "sync_interval = 20\n",
        "env = gym.make(\n",
        "    \"LunarLander-v2\",\n",
        "    continuous = False,\n",
        "    gravity = -10.0,\n",
        "    enable_wind = False,\n",
        "    wind_power = 15.0,\n",
        "    turbulence_power = 1.5,\n",
        ")\n",
        "agent = DQNAgent()\n",
        "reward_log = []\n",
        "\n",
        "for episode in tqdm(range(episodes)):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = agent.get_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        agent.update(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "    reward_log.append(total_reward)\n",
        "    if episode % sync_interval == 0:\n",
        "        agent.sync_qnet()\n",
        "        # print(f\"episode: {episode}, reward: {total_reward}\")\n",
        "\n",
        "    reward_log.append(total_reward)\n",
        "    if episode % 100 == 0:\n",
        "        print(f\"episode: {episode}, reward: {total_reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6025f159b0941cebd54c23d663d73df",
            "384de4d2483842128e56ec8003851fa7",
            "4569804c1720490aa151e3b896f52dd7",
            "0c2cbc08915d4d7ab4949ab99993dd46",
            "18ff258b8f60414a9bdd26b06b3bb00d",
            "c3cc8d779e074304bc17f76b9b0168de",
            "ee1468144bea42718f73a7362bc29b0e",
            "cf669879f80f4e0ebc53a2e0ed0d9bca",
            "61087736c8c549f3a7c2358408735d9b",
            "8656ef6341f24908ba41bd373f83213f",
            "d262a946beca499e97a57b80bf7be2f7"
          ]
        },
        "id": "yGDeztiK61bT",
        "outputId": "dcefd900-4f28-4028-dbf0-59071526ad90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6025f159b0941cebd54c23d663d73df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 0, reward: -438.54453129636676\n",
            "episode: 0, reward: -438.54453129636676\n",
            "episode: 20, reward: -439.162422798854\n",
            "episode: 40, reward: -64.22651194335799\n",
            "episode: 60, reward: -280.8380546655906\n",
            "episode: 80, reward: -719.1272887604861\n",
            "episode: 100, reward: -110.76146624297515\n",
            "episode: 100, reward: -110.76146624297515\n",
            "episode: 120, reward: -165.14246246767982\n",
            "episode: 140, reward: -3.2405586657794174\n",
            "episode: 160, reward: -238.30744525774003\n",
            "episode: 180, reward: -85.43564950577026\n",
            "episode: 200, reward: -102.81957716242648\n",
            "episode: 200, reward: -102.81957716242648\n",
            "episode: 220, reward: -102.58314735738392\n",
            "episode: 240, reward: 56.028349954183994\n",
            "episode: 260, reward: -97.97432986614284\n",
            "episode: 280, reward: -82.4068194215772\n",
            "episode: 300, reward: -85.94505148262476\n",
            "episode: 300, reward: -85.94505148262476\n",
            "episode: 320, reward: -177.0821426937424\n",
            "episode: 340, reward: -121.70618612976018\n",
            "episode: 360, reward: -177.53805202242836\n",
            "episode: 380, reward: -98.90496751897196\n",
            "episode: 400, reward: -68.28622587641654\n",
            "episode: 400, reward: -68.28622587641654\n",
            "episode: 420, reward: -98.31668052779256\n",
            "episode: 440, reward: -87.2522217501367\n",
            "episode: 460, reward: -120.23745456801845\n",
            "episode: 480, reward: -94.54272800369255\n",
            "episode: 500, reward: -137.70409436020486\n",
            "episode: 500, reward: -137.70409436020486\n",
            "episode: 520, reward: -86.48970239957123\n",
            "episode: 540, reward: -26.70155167161317\n",
            "episode: 560, reward: -100.01804574539395\n",
            "episode: 580, reward: -97.4284050335823\n",
            "episode: 600, reward: -129.70546274823207\n",
            "episode: 600, reward: -129.70546274823207\n",
            "episode: 620, reward: -16.032891513691915\n",
            "episode: 640, reward: -177.9215627637365\n",
            "episode: 660, reward: -7.350331402744469\n",
            "episode: 680, reward: 77.22664997046729\n",
            "episode: 700, reward: -104.46749429391673\n",
            "episode: 700, reward: -104.46749429391673\n",
            "episode: 720, reward: 5.183210197047772\n",
            "episode: 740, reward: -61.65394593228188\n",
            "episode: 760, reward: -8.935948338690986\n",
            "episode: 780, reward: 213.72042596122625\n",
            "episode: 800, reward: 175.21139776750147\n",
            "episode: 800, reward: 175.21139776750147\n",
            "episode: 820, reward: 209.51905616811865\n",
            "episode: 840, reward: -6.9022672406859495\n",
            "episode: 860, reward: -118.32794204855585\n",
            "episode: 880, reward: -168.6847521703066\n",
            "episode: 900, reward: 181.58935596432983\n",
            "episode: 900, reward: 181.58935596432983\n",
            "episode: 920, reward: -40.02616419735195\n",
            "episode: 940, reward: -154.40126141277594\n",
            "episode: 960, reward: 244.03435102916166\n",
            "episode: 980, reward: 238.00555153065812\n",
            "episode: 1000, reward: 258.56776429913145\n",
            "episode: 1000, reward: 258.56776429913145\n",
            "episode: 1020, reward: 213.05299212985219\n",
            "episode: 1040, reward: 241.4016147960242\n",
            "episode: 1060, reward: 230.98494063673112\n",
            "episode: 1080, reward: -16.833540601190265\n",
            "episode: 1100, reward: -118.67468288276659\n",
            "episode: 1100, reward: -118.67468288276659\n",
            "episode: 1120, reward: 6.109649667585316\n",
            "episode: 1140, reward: 64.11515028216144\n",
            "episode: 1160, reward: 253.84322307242354\n",
            "episode: 1180, reward: -41.829895829866075\n",
            "episode: 1200, reward: 234.88625432347462\n",
            "episode: 1200, reward: 234.88625432347462\n",
            "episode: 1220, reward: 226.21338036109552\n",
            "episode: 1240, reward: 201.90781737298067\n",
            "episode: 1260, reward: -205.91489056193745\n",
            "episode: 1280, reward: 252.32852196709075\n",
            "episode: 1300, reward: -156.14890619702186\n",
            "episode: 1300, reward: -156.14890619702186\n",
            "episode: 1320, reward: 258.87774973719564\n",
            "episode: 1340, reward: 228.6977472451022\n",
            "episode: 1360, reward: -139.12793556650252\n",
            "episode: 1380, reward: -134.23450782718854\n",
            "episode: 1400, reward: 216.0076274555511\n",
            "episode: 1400, reward: 216.0076274555511\n",
            "episode: 1420, reward: 4.0508774589846155\n",
            "episode: 1440, reward: -15.940085768811215\n",
            "episode: 1460, reward: 37.87312059262405\n",
            "episode: 1480, reward: -15.13266428681327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4. DQN で推論\n",
        "\n",
        "colaboratory 上に描画"
      ],
      "metadata": {
        "id": "I5sb3lj5EJxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "# 推論\n",
        "env = gym.make(\n",
        "    \"LunarLander-v2\",\n",
        "    continuous = False,\n",
        "    gravity = -10.0,\n",
        "    enable_wind = False,\n",
        "    wind_power = 15.0,\n",
        "    turbulence_power = 1.5,\n",
        ")\n",
        "env.action_space.seed(42)\n",
        "state = env.reset(seed=42)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in tqdm(range(2000)):\n",
        "        action: int = agent.get_action(state, deterministic=True)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        state = observation\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(\n",
        "            Image.fromarray(env.render(mode='rgb_array'))\n",
        "        )\n",
        "        time.sleep(0.08)\n",
        "        if done:\n",
        "            env.reset()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "__OWf-9_XYNM",
        "outputId": "f6239385-87d9-4d5b-a74c-ce85507dc602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=600x400>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "録画する場合 (こちらの動作は未確認)"
      ],
      "metadata": {
        "id": "dSk931Z4EYor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# 推論\n",
        "env = gym.make(\n",
        "    \"LunarLander-v2\",\n",
        "    continuous = False,\n",
        "    gravity = -10.0,\n",
        "    enable_wind = False,\n",
        "    wind_power = 15.0,\n",
        "    turbulence_power  = 1.5,\n",
        ")\n",
        "env.action_space.seed(42)\n",
        "\n",
        "# 録画用の RecordVideo ラッパーの作成\n",
        "video_path = \"/content/lunar_lander_video\"  # 保存先\n",
        "env = RecordVideo(env, video_path)\n",
        "\n",
        "state = env.reset(seed=42)\n",
        "\n",
        "\n",
        "\n",
        "# # エピソードの実行\n",
        "# num_episodes = 5\n",
        "# for episode in range(num_episodes):\n",
        "#     observation = env.reset()\n",
        "\n",
        "#     while not done:\n",
        "#         action = env.action_space.sample()  # ランダムな行動の選択\n",
        "#         observation, reward, done, _ = env.step(action)\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for step in tqdm(range(2000)):\n",
        "        action: int = agent.get_action(state)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        # state = observation\n",
        "        # display.clear_output(wait=True)\n",
        "        # display.display(\n",
        "        #     Image.fromarray(env.render(mode='rgb_array'))\n",
        "        # )\n",
        "        # time.sleep(0.08)\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            print(f\"Step {step + 1}, Total Reward: {total_reward}\")\n",
        "            total_reward = 0\n",
        "            env.reset()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "j47LfRCvGwfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}